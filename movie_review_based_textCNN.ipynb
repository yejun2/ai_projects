{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1VbpJfblkYQNUEPWAXhKcBuHYZvyg7G1M",
      "authorship_tag": "ABX9TyPl8BUEw5xEYqYygem/is0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yejun2/ai_projects/blob/main/movie_review_based_textCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***영화 리뷰 데이터 링크***\n",
        "\n",
        "https://github.com/e9t/nsmc/"
      ],
      "metadata": {
        "id": "EA0Na2glaIAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***참조 블로그***"
      ],
      "metadata": {
        "id": "rQIvPnJ1tPtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://kaya-dev.tistory.com/6\n",
        "\n",
        "https://wikidocs.net/50739"
      ],
      "metadata": {
        "id": "oEqbTzdUtSJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***데이터 읽어오기***"
      ],
      "metadata": {
        "id": "EqtjfnCpaON2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.6.0"
      ],
      "metadata": {
        "id": "6gVQ1-VoOo3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data = pd.read_table(\"drive/MyDrive/Colab Notebooks/ratings_train.txt\")\n",
        "test_data = pd.read_table(\"drive/MyDrive/Colab Notebooks/ratings_test.txt\")"
      ],
      "metadata": {
        "id": "J9Wnl6Z4aVbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 양이 너무 많아 프로젝트 진행에 차질이 있어 데이터 축소\n",
        "(아이디어 토큰화한 데이터를 저장할 때, join을 써서 쉼표로 구분하여 저장하고 로드하여 사용하면 가진 데이터를 전체 이용할수 있을거 같음)"
      ],
      "metadata": {
        "id": "bY-PVkiuQb3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 갯수 확인"
      ],
      "metadata": {
        "id": "LRi8EwAUQsOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8e_mojQbks",
        "outputId": "40e08956-7321-4d00-a6a6-e6c18f20fa93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150000\n",
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data[:40000]\n",
        "test_data = test_data[:5000]"
      ],
      "metadata": {
        "id": "mHnAWru4Qrnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 갯수 확인"
      ],
      "metadata": {
        "id": "mglPce_CQ5KI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTbz389UQ5io",
        "outputId": "b7a6d5dd-a9bd-41ed-fd67-5a7f957fb623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "document를 전처리할 메소드 생성"
      ],
      "metadata": {
        "id": "7zYVck_EcICK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(doc):\n",
        "  doc = re.sub('[\\t\\r\\n\\f\\v]', ' ', str(doc))\n",
        "  doc = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ]', ' ', str(doc))\n",
        "  doc = \" \".join(doc.split())\n",
        "  return doc\n",
        "\n",
        "def document_preprocessing(data):\n",
        "  data.drop_duplicates(subset = ['document'], inplace=True)\n",
        "  data.dropna(axis=0)\n",
        "  data['document'] = [text_preprocessing(x) for x in tqdm(data['document'])]\n",
        "  return data"
      ],
      "metadata": {
        "id": "67KI0bu7bnEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_data와 test_data를 전처리"
      ],
      "metadata": {
        "id": "m6AyyfgDGBIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = document_preprocessing(train_data)\n",
        "test_data = document_preprocessing(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufRdvy4_F-Xa",
        "outputId": "893ce451-0ea4-4029-b27f-3a7b95b1effa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39350/39350 [00:00<00:00, 164708.21it/s]\n",
            "100%|██████████| 4969/4969 [00:00<00:00, 157820.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 데이터 저장"
      ],
      "metadata": {
        "id": "2f4ZnwQslKEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv(\"preprocessed_train.csv\")\n",
        "test_data.to_csv(\"preprocessed_test.csv\")"
      ],
      "metadata": {
        "id": "cKyzQaprlOCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***colab에서 OKT를 사용할 수 있는 환경을 만들어주는 코드***"
      ],
      "metadata": {
        "id": "K8Bd4cDWqXJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
      ],
      "metadata": {
        "id": "ciLlabWBrUd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "konply를 import해오고 okt 변수 생성"
      ],
      "metadata": {
        "id": "KlGGfMGBETR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "nPuBNq-pqclU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화하는 메소드를 생성"
      ],
      "metadata": {
        "id": "74Hkb7ohEzmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing_method(input_data):\n",
        "  stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "  tokenized_data = []\n",
        "  for sentence in input_data:\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]\n",
        "    tokenized_data.append(stopwords_removed_sentence)\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "3hCwvEjB7gmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokening_method로 토큰화된 train_data['document']를 생성"
      ],
      "metadata": {
        "id": "COHFM9s_Hn_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = tokenizing_method(train_data['document'])"
      ],
      "metadata": {
        "id": "-zJg7q1JFsS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "확인해보는 코드"
      ],
      "metadata": {
        "id": "_17VyK1YH1_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_data[:10])"
      ],
      "metadata": {
        "id": "xgxt_CoOH3vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화된 데이터를 저장하는 코드"
      ],
      "metadata": {
        "id": "1c102WqFIK8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = pd.DataFrame(tokenized_data)\n",
        "tokenized_data.to_csv(\"/content/drive/MyDrive/tokenized_train_data.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "0uPms2WRLDWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data_label = pd.DataFrame(tokenized_data, train_data['label'])\n",
        "tokenized_data_label.to_csv(\"/content/drive/MyDrive/tokenized_train_data_label.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "UXt3thPKyd1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화된 데이터를 불러오고 확인하는 코드"
      ],
      "metadata": {
        "id": "L4xb5PHEJKhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_tokenized_data = pd.read_csv(\"/content/drive/MyDrive/tokenized_train_data.csv\")\n",
        "print(saved_tokenized_data.head(10))"
      ],
      "metadata": {
        "id": "IoDzQkn3MO_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "embedding_model = Word2Vec(sentences=tokenized_data,\n",
        "                           sg=1,\n",
        "                           vector_size=100,\n",
        "                           window=2,\n",
        "                           min_count=1,\n",
        "                           workers=4\n",
        "                           )\n"
      ],
      "metadata": {
        "id": "6yVOVeMG-5xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_model)\n",
        "model_result = embedding_model.wv.most_similar('재미')\n",
        "print(model_result)"
      ],
      "metadata": {
        "id": "cPExEAGq_qYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n"
      ],
      "metadata": {
        "id": "O5DmKRWBIVrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.wv.save_word2vec_format('/content/drive/MyDrive/review_tokens_w2v') # 모델 저장"
      ],
      "metadata": {
        "id": "d4s6p0S8IVU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/review_tokens_w2v') # 모델 로드\n",
        "\n",
        "model_result = loaded_model.most_similar(\"추천\")\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHvNBf6y5XUA",
        "outputId": "55a88fd0-a5a9-44de-ee68-0e57b35a666b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('강력', 0.8423237204551697), ('강추', 0.8385577201843262), ('적극', 0.8177915811538696), ('권하다', 0.7926265597343445), ('해드리다', 0.76430344581604), ('보삼', 0.7491391897201538), ('소장', 0.7400360703468323), ('남자라면', 0.7314027547836304), ('감사', 0.730396032333374), ('재방송', 0.7297847867012024)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "from torchtext.data import Field"
      ],
      "metadata": {
        "id": "jMUIFmRoIgsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import TabularDataset"
      ],
      "metadata": {
        "id": "DyjVYWhZPY8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "SUkSn5Ch1HYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "def preprocess(text):\n",
        "    #stopword를 제거합니다.\n",
        "    word = [t for t in text if t not in stopwords]\n",
        "    return word\n",
        "\n",
        "ID = Field(sequential= False, use_vocab = False)\n",
        "\n",
        "IDX = Field(sequential = False, use_vocab = False)\n",
        "#사용할 예정\n",
        "TEXT = Field(sequential = True, batch_first = True,\n",
        "\t\t\tis_target = False, use_vocab = True,\n",
        "\t\t\ttokenize = okt.morphs,\n",
        "\t\t\tpreprocessing = preprocess) #형태소 분석 + 형태소 분석 이후 추가 처리 진행!\n",
        "LABEL = Field(sequential = False,batch_first = True,is_target = True,\n",
        "\t\t\tuse_vocab = False,dtype = torch.float32)\n",
        "\n",
        "#필드 정의\n",
        "field = [('idx', IDX),('id',ID),('document',TEXT),('label',LABEL)]\n",
        "\n",
        "#이전에 처리한 문서를 불러와서 훈련에 사용할 데이터로 만들어줍니다.\n",
        "train_dataset, validation_dataset = TabularDataset.splits(\n",
        "    path = '/content/', #반드시 있어야함!\n",
        "    train = 'preprocessed_train.csv',\n",
        "    validation = \"preprocessed_test.csv\",\n",
        "    format = 'csv',\n",
        "    fields = field,\n",
        "    skip_header = True,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "KITV1Vs0Pvf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0].document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ZTuVKg14fO",
        "outputId": "a5fb93d9-32ae-4e22-ea4f-e10ad94786ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['아', '더빙', '진짜', '짜증나네요', '목소리']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://wikidocs.net/60314"
      ],
      "metadata": {
        "id": "gO6EV4GeWc-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.data import BucketIterator\n",
        "\n",
        "vectors = Vectors(name='/content/drive/MyDrive/review_tokens_w2v')\n",
        "\n",
        "TEXT.build_vocab(train_dataset, vectors = vectors, min_freq = 1, max_size = None)\n",
        "LABEL.build_vocab(train_dataset)\n",
        "IDX.build_vocab(train_dataset)\n",
        "ID.build_vocab(train_dataset)\n",
        "\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "train_iter, validation_iter = BucketIterator.splits(\n",
        "    datasets = (train_dataset, validation_dataset),\n",
        "    batch_size = 20,\n",
        "    device = device,\n",
        "    sort = False\n",
        ")\n",
        "\n",
        "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vdYFXirWcoA",
        "outputId": "d02bf55c-1c57-4836-bb09-89758677a342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "임베딩 벡터의 개수와 차원 : torch.Size([47156, 100]) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기까지"
      ],
      "metadata": {
        "id": "-nEXfpkcbPoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)\n",
        "\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        emb_x = self.embed(x)\n",
        "        #print(emb_x.shape)\n",
        "        emb_x = emb_x.unsqueeze(1)\n",
        "        #print(emb_x.shape)\n",
        "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]\n",
        "        #print(con_x[0].shape)\n",
        "        #print(con_x[1].shape)\n",
        "        #print(con_x[2].shape)\n",
        "        '''\n",
        "        print(\"size--\")\n",
        "        for x in con_x:\n",
        "          print(x.squeeze(-1).shape)\n",
        "        '''\n",
        "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]\n",
        "\n",
        "        '''\n",
        "        for x in pool_x:\n",
        "          print(x.shape)\n",
        "        print(\"torch cat---\")\n",
        "        '''\n",
        "        fc_x = torch.cat(pool_x, dim=1)\n",
        "        #print(fc_x.shape)\n",
        "        fc_x = fc_x.squeeze(-1)\n",
        "        #print(fc_x.shape)\n",
        "        fc_x = self.dropout(fc_x)\n",
        "\n",
        "        logit = self.fc(fc_x)\n",
        "\n",
        "        return logit"
      ],
      "metadata": {
        "id": "cvk8vrQ-W9jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YwALhVjCtw9r"
      },
      "outputs": [],
      "source": [
        "def train_model(model, device, train_itr, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    corrects, train_loss = 0.0,0\n",
        "    batch_idx = 1\n",
        "    for batch in train_itr:\n",
        "\n",
        "        id, idx, text, target = batch.id, batch.idx, batch.document, batch.label\n",
        "        target = target.type(torch.LongTensor)\n",
        "        #text = torch.transpose(text, 0, 1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        #print(text.shape)\n",
        "        #print(target.shape)\n",
        "        optimizer.zero_grad()\n",
        "        #print(\"to model______\")\n",
        "        logit = model(text)\n",
        "        #print(\"out model______\")\n",
        "        #print(logit.data)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "        #break\n",
        "        #print(batch_idx)\n",
        "        batch_idx+=1\n",
        "    train_loss /= len(train_itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
        "\n",
        "    return train_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FI__d6jVtw9s"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, device, itr):\n",
        "\n",
        "    model.eval()\n",
        "    corrects, test_loss = 0.0, 0\n",
        "\n",
        "    for batch in itr:\n",
        "\n",
        "        text = batch.document\n",
        "        target = batch.label\n",
        "        target = target.type(torch.LongTensor)\n",
        "        #text = torch.transpose(text, 0, 1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "\n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "\n",
        "    test_loss /= len(itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_test_acc = -1\n",
        "\n",
        "for epoch in range(1, 3+1):\n",
        "\n",
        "    tr_loss, tr_acc = train_model(model, device, train_iter, optimizer)\n",
        "    #break\n",
        "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
        "\n",
        "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
        "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
        "\n",
        "    if val_acc > best_test_acc:\n",
        "        best_test_acc = val_acc\n",
        "\n",
        "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/TextCNN_Best_Validation\")\n",
        "\n",
        "    print('-----------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "7tQNjYVaXM3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/TextCNN_Best_Validation\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "yBHD1b2JBgsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aef737b-6700-493d-b909-4eb7de1a950d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextCNN(\n",
              "  (embed): Embedding(47156, 100)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
              "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
              "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "hG276j4wF9Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sent = preprocess(sentence)\n",
        "        sent = okt.morphs(sentence)\n",
        "        sent = torch.tensor([TEXT.vocab.stoi[i] for i in sent])\n",
        "        if len(sent) < 6:\n",
        "          sent = F.pad(sent,pad = (1,6-len(sent)-1),value = 1)\n",
        "        sent = sent.unsqueeze(dim = 0) #for batch\n",
        "        output = model(sent)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "FIfmJJNkF5uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "while True:\n",
        "  user = input(\"테스트 할 리뷰를 작성하세요 : \")\n",
        "  if user == '0':\n",
        "    break\n",
        "  model = model.to('cpu')\n",
        "  pred = predict(model,user)\n",
        "  pred = torch.max(pred,1)[1].item()\n",
        "  if (pred == 1) :\n",
        "    print(\"긍정적인 리뷰입니다.\")\n",
        "  else :\n",
        "    print(\"부정적인 리뷰입니다.\")\n",
        "  print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "co44er7iHB-k",
        "outputId": "7b09b133-f2d8-44e6-f4cd-9b35f9fc5a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 할 리뷰를 작성하세요 : 지루함\n",
            "부정적인 리뷰입니다.\n",
            "0\n",
            "테스트 할 리뷰를 작성하세요 : 진짜 재미없음\n",
            "부정적인 리뷰입니다.\n",
            "0\n",
            "테스트 할 리뷰를 작성하세요 : 다시는 보고싶지 않다\n",
            "부정적인 리뷰입니다.\n",
            "0\n",
            "테스트 할 리뷰를 작성하세요 : 마음 따스해지는 영화였다\n",
            "긍정적인 리뷰입니다.\n",
            "1\n",
            "테스트 할 리뷰를 작성하세요 : ㅋㅋㅋㅋㅋㅋ 웃긴 영화다 코미디 영화 찾는 분께 추천\n",
            "긍정적인 리뷰입니다.\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ddf1ddf71284>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"테스트 할 리뷰를 작성하세요 : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}